---
title: "walk_through-1"
author: "Julie E Gervis"
date: "1/30/2021"
output: html_document
---

## Step 1

In order to run SPCH, you first need to create some "prerequesite" functions - functions that you will include
in the main function. I started by creating functions to run KCA and Ward's D on a given dataset ("data"), for 
a specified number of clusters (Ck), with the output being the cluster assignments.

```{r}
# KCA function
kca.fun<-function(data, Ck){
  as.numeric(kmeans(data, Ck, nstart=50)$cluster)
}

# Ward's D function
wardD.fun<-function(data, Ck){
  as.numeric(cutree(hclust(dist(data), method = "ward.D"), Ck))
}
```

Notice that the inputs for both functions are the same. This will be important, for them to be seamlessly 
incorporated into the parent function.

Next, I created the parent shcv function. The inputs to this function are:
- "data" - the dataset that you are using
- "Ck" - a specified number of clusters (I will use inputs from 2:10, based on existing literature and with 
   consideration of the samepl size)
- FUN - this will be how the functions (kca.fun and wardD.fun will be included)

```{r}
shcv.fun<-function(data, Ck, FUN){
  # Set.seed to ensure results are replicatable
  set.seed(123, kind="default")
  
  # Create temporary matrix to store data; 20 rows (20 estimates for each Ck) x 2 cols (1 for each index)
  temp<-matrix(NA,20,2, dimnames = list(c(1:20), c(paste("ARI.", Ck, sep=""), 
                                                   paste("CramV.", Ck, sep=""))))
  
  # Use for loop to generate 10 random test/train sets; for each set, generate 2 estimates for each index (ARI and CramV)
  for (i in 1:10){
    # 1. split data into train and test set
    train.n<-sample(nrow(data), nrow(data)*0.5, replace=F) 
    train.dat<-data[train.n,]; test.dat<-data[-(train.n),]
    
    # 2. Run cluster algorithm on train.dat
    train.clust<-FUN(train.dat, Ck)
    
    # 3. Perform K- Nearest Neighbors on test.dat using train.clust
    test.knn<-knn(train.dat, test.dat, cl=train.clust, Ck, use.all = T, prob=T, l=0.5)
    
    # 4. Run cluster algorithm on test.dat
    test.clust<-FUN(test.dat, Ck)
    
    # 5. Compute ari & cramer's V between test.clust and test.knn 
    ## a. store data in "temp" matrix
    temp[i,1]<- adj.rand.index(test.clust, as.numeric(test.knn))
    temp[i,2]<- cramerV(test.clust, as.numeric(test.knn))
    
    # 6.Repeate steps 2-5 using test sample as the "train" sample
    test.clust<-FUN(test.dat, Ck)
    train.knn<-knn(test.dat, train.dat, cl=test.clust, Ck, use.all = T, prob=T, l=0.5)
    train.clust<-FUN(train.dat, Ck)
    
    ## a. store data temporarily
    temp[i+10,1]<- adj.rand.index(train.clust, as.numeric(train.knn))
    temp[i+10,2]<- cramerV(train.clust, as.numeric(train.knn))
  }
  
  # Print temp matrix with 20 estimates for each index per alg for each 
  return(temp)
}
```

```{r setup, include=F}


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.




